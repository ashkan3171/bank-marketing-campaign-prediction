# ğŸ“Š Bank Marketing Campaign Success Prediction

## ğŸš€ Project Overview
This project predicts the success of a **bank marketing campaign** using machine learning.  
We explore different models and techniques to improve accuracy and recall,  
especially given the **imbalanced dataset**.  

ğŸ”¹ **Dataset**: The dataset contains customer details and past interactions with the bank.  
ğŸ”¹ **Goal**: Predict whether a customer will **subscribe** (`yes/no`).  
ğŸ”¹ **Techniques Used**:
   - Exploratory Data Analysis (EDA)
   - Feature Engineering & Data Preprocessing
   - Handling Imbalanced Data using **SMOTE**
   - Model Training: **Logistic Regression, Random Forest, XGBoost**
   - Hyperparameter Tuning with **RandomizedSearchCV**
   - Evaluation using **Precision, Recall, F1-Score, and ROC-AUC**

---

## ğŸ› ï¸ Project Workflow
1ï¸âƒ£ **Data Loading & Exploration**
   - Checked for missing values and outliers
   - Analyzed target variable imbalance  
   
2ï¸âƒ£ **Feature Engineering**
   - Converted categorical features using **One-Hot & Ordinal Encoding**
   - Scaled numerical features using **StandardScaler**
   - Created new features (`pdays_category`, `previous_category`, `balance_category`)

3ï¸âƒ£ **Handling Imbalanced Data**
   - Used **SMOTE** to balance the dataset
   - Stratified Train-Test Split  

4ï¸âƒ£ **Model Training & Evaluation**
   - **Logistic Regression** (Baseline Model)
   - **Random Forest** (Better precision-recall balance)
   - **XGBoost** (Final model with the best trade-off)
   - Tuned **hyperparameters** for optimal performance  

---

## ğŸ† Model Performance Summary
| Model  | Accuracy | Precision (Yes) | Recall (Yes) | F1-Score (Yes) |
|--------|---------|----------------|-------------|-------------|
| Logistic Regression | 85% | 42% | **81%** | 55% |
| Random Forest | 90% | 58% | **55%** | **56%** |
| XGBoost | 90% | **59%** | 54% | **56%** |

---
